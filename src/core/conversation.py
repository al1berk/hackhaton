# src/core/conversation.py

from typing import TypedDict, List, Literal
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
import asyncio
import json
from datetime import datetime

from core.config import Config
from agents.research_crew import AsyncCrewAIA2AHandler
from core.vector_store import VectorStore

class ConversationState(TypedDict):
    messages: List[BaseMessage]
    current_intent: str
    needs_crew_ai: bool
    crew_ai_task: str
    user_context: dict
    conversation_summary: str
    research_data: dict
    websocket_callback: object
    pending_action: str
    research_completed: bool
    rag_context: str
    has_pdf_context: bool
    chat_id: str
    chat_manager: object  # Chat manager referansƒ±

class AsyncLangGraphDialog:
    def __init__(self, websocket_callback=None, chat_id=None, chat_manager=None):
        self.llm = ChatGoogleGenerativeAI(
            model=Config.GEMINI_MODEL,
            google_api_key=Config.GOOGLE_API_KEY,
            temperature=Config.GEMINI_TEMPERATURE,
        )
        
        self.websocket_callback = websocket_callback
        self.chat_id = chat_id
        self.chat_manager = chat_manager
        self.crew_handler = AsyncCrewAIA2AHandler(websocket_callback)
        
        # Chat-specific vector store olu≈ütur
        self.vector_store = VectorStore(Config.VECTOR_STORE_PATH, chat_id=chat_id)
        
        self.graph = self.create_conversation_graph()
        
        self.conversation_state = ConversationState(
            messages=[SystemMessage(content=Config.SYSTEM_PROMPT)],
            current_intent="",
            needs_crew_ai=False,
            crew_ai_task="",
            user_context={},
            conversation_summary="",
            research_data={},
            websocket_callback=websocket_callback,
            pending_action="",
            research_completed=False,
            rag_context="",
            has_pdf_context=False,
            chat_id=chat_id or "",
            chat_manager=chat_manager
        )
    
    def create_conversation_graph(self):
        workflow = StateGraph(ConversationState)
        
        workflow.add_node("handle_confirmation", self.handle_confirmation_node)
        workflow.add_node("intent_analysis", self.intent_analysis_node)
        workflow.add_node("rag_search", self.rag_search_node)
        workflow.add_node("no_pdf_available", self.no_pdf_available_node)
        workflow.add_node("crew_research_agent", self.crew_research_agent_node)
        workflow.add_node("research_presentation", self.research_presentation_node)
        workflow.add_node("gemini_response", self.gemini_response_node)
        workflow.add_node("ask_confirmation", self.ask_confirmation_node)
        workflow.add_node("research_followup", self.research_followup_node)
        
        workflow.set_conditional_entry_point(
            self.route_initial_input,
            {"continue_to_intent": "intent_analysis", "handle_confirmation": "handle_confirmation"}
        )
        
        workflow.add_conditional_edges(
            "intent_analysis",
            self.should_call_crew_or_ask_or_rag_or_no_pdf,
            {
                "crew_research": "crew_research_agent", 
                "ask_confirmation": "ask_confirmation", 
                "rag_search": "rag_search", 
                "no_pdf_available": "no_pdf_available",
                "gemini": "gemini_response"
            }
        )

        workflow.add_conditional_edges(
            "handle_confirmation",
            self.decide_after_confirmation,
            {"start_research": "crew_research_agent", "cancel": "gemini_response"}
        )
        
        workflow.add_edge("rag_search", "gemini_response")
        workflow.add_edge("no_pdf_available", END)
        workflow.add_edge("crew_research_agent", "research_presentation")
        workflow.add_edge("research_presentation", "research_followup")
        workflow.add_edge("research_followup", END)
        workflow.add_edge("gemini_response", END)
        workflow.add_edge("ask_confirmation", END)

        return workflow.compile()

    def should_call_crew_or_ask_or_rag_or_no_pdf(self, state: ConversationState) -> Literal["crew_research", "ask_confirmation", "rag_search", "no_pdf_available", "gemini"]:
        intent = state["current_intent"]
        if intent in ["web_research", "ask_confirmation", "rag_search", "no_pdf_available"]:
            return intent
        return "gemini"

    def route_initial_input(self, state: ConversationState) -> Literal["continue_to_intent", "handle_confirmation"]:
        if state.get("pending_action"):
            return "handle_confirmation"
        return "continue_to_intent"

    def handle_confirmation_node(self, state: ConversationState) -> ConversationState:
        last_message = state["messages"][-1].content.lower()
        
        if any(keyword in last_message for keyword in ["evet", "onayla", "ba≈ülat", "yap"]):
            state["current_intent"] = state["pending_action"]
            state["needs_crew_ai"] = True
        else:
            state["current_intent"] = "general_chat"
            state["needs_crew_ai"] = False
            state["messages"].append(AIMessage(content="Anla≈üƒ±ldƒ±, ara≈ütƒ±rma ba≈ülatƒ±lmadƒ±. Size ba≈üka nasƒ±l yardƒ±mcƒ± olabilirim?"))

        state["pending_action"] = ""
        return state

    def decide_after_confirmation(self, state: ConversationState) -> Literal["start_research", "cancel"]:
        if state["needs_crew_ai"]:
            return "start_research"
        return "cancel"

    async def ask_confirmation_node(self, state: ConversationState) -> ConversationState:
        topic = state["crew_ai_task"]
        message_content = f"'{topic}' konusu hakkƒ±nda kapsamlƒ± bir web ara≈ütƒ±rmasƒ± ba≈ülatmamƒ± onaylƒ±yor musunuz?"
        
        if self.websocket_callback:
            await self.websocket_callback(json.dumps({
                "type": "confirmation_request", 
                "content": message_content, 
                "timestamp": datetime.utcnow().isoformat(),
                "chat_id": self.chat_id
            }))
        
        state["pending_action"] = "web_research"
        return state

    async def rag_search_node(self, state: ConversationState) -> ConversationState:
        """PDF dok√ºmanlarƒ±nda arama yapar"""
        try:
            last_message = state["messages"][-1].content
            
            # Vekt√∂r deposunda ara
            search_results = self.vector_store.search_similar(
                query=last_message,
                n_results=Config.RAG_TOP_K
            )
            
            if search_results:
                # Benzerlik skoruna g√∂re filtrele
                relevant_results = [
                    result for result in search_results 
                    if result['similarity'] >= Config.RAG_SIMILARITY_THRESHOLD
                ]
                
                if relevant_results:
                    # RAG context'i olu≈ütur
                    rag_context = self.format_rag_context(relevant_results)
                    state["rag_context"] = rag_context
                    state["has_pdf_context"] = True
                    
                    if self.websocket_callback:
                        await self.websocket_callback(json.dumps({
                            "type": "rag_found",
                            "message": f"üìö {len(relevant_results)} ilgili dok√ºman par√ßasƒ± bulundu (Sohbet: {self.chat_id})",
                            "timestamp": datetime.utcnow().isoformat(),
                            "chat_id": self.chat_id
                        }))
                else:
                    state["rag_context"] = ""
                    state["has_pdf_context"] = False
            else:
                state["rag_context"] = ""
                state["has_pdf_context"] = False
                
        except Exception as e:
            print(f"‚ùå RAG search error (Chat: {self.chat_id}): {e}")
            state["rag_context"] = ""
            state["has_pdf_context"] = False
        
        return state

    def intent_analysis_node(self, state: ConversationState) -> ConversationState:
        last_message = state["messages"][-1].content.strip().lower()
        original_message = state["messages"][-1].content.strip()
        
        # Force web research flag'ini kontrol et
        force_web_research = state.get("force_web_research", False)
        
        print(f"üîç Intent Analysis - Message: '{last_message[:50]}...', Force Web Research: {force_web_research}")
        
        # Ara≈ütƒ±rma tamamlandƒ±ysa ve research data varsa
        if state.get("research_completed", False) and state.get("research_data"):
            research_keywords = ["ara≈ütƒ±rma", "rapor", "bulgu", "sonu√ß", "detay", "a√ßƒ±kla", "anlatƒ±r mƒ±sƒ±n", 
                            "nedir", "nasƒ±l", "ne demek", "anlat", "a√ßƒ±klayabilir", "daha fazla bilgi"]
            
            if any(keyword in last_message for keyword in research_keywords):
                state["current_intent"] = "research_question"
                state["needs_crew_ai"] = False
                print(f"‚úÖ Intent: research_question")
                return state
        
        # √ñNCE web ara≈ütƒ±rmasƒ± flag'ini kontrol et
        if force_web_research:
            state["current_intent"] = "web_research"
            state["crew_ai_task"] = original_message
            state["needs_crew_ai"] = True
            print(f"‚úÖ Intent: web_research (forced)")
            return state
        
        # RAG kontrol√º - DAHA SPESIFIK KRITERLER
        if Config.RAG_ENABLED:
            vector_stats = self.vector_store.get_stats()
            has_documents = vector_stats.get("total_documents", 0) > 0
            print(f"üìö PDF Documents: {has_documents}, Total: {vector_stats.get('total_documents', 0)}")
            
            if has_documents:
                # Direkt PDF referanslarƒ±
                direct_pdf_references = [
                    "bu dok√ºman", "bu dokuman", "bu dosya", "bu pdf", "bu rapor",
                    "bu belge", "y√ºklediƒüim", "yukledƒ±gƒ±m", "g√∂nderdiƒüim", "gonderdigim",
                    "dok√ºmanƒ±", "dokumanƒ±", "dosyayƒ±", "pdf'i", "raporu", "belgeyi"
                ]
                
                # PDF i√ßerik sorularƒ±
                pdf_content_questions = [
                    "√∂zet", "√∂zetle", "i√ßerik", "i√ßinde", "neler var", "ne diyor",
                    "bahsediyor", "yaziyor", "yazƒ±yor", "anlatƒ±yor", "g√∂steriyor",
                    "a√ßƒ±klƒ±yor", "hangi konular", "nasƒ±l a√ßƒ±klƒ±yor"
                ]
                
                # Dosya ismi referanslarƒ±
                uploaded_files = vector_stats.get("documents", [])
                file_name_matches = []
                for doc in uploaded_files:
                    filename = doc.get("filename", "").lower()
                    if filename:
                        # Dosya adƒ±nƒ±n ana kƒ±smƒ±nƒ± al (uzantƒ±sƒ±z)
                        name_without_ext = filename.replace(".pdf", "").replace("-", " ").replace("_", " ")
                        name_parts = [part for part in name_without_ext.split() if len(part) > 3]
                        
                        # Bu dosya isminin par√ßalarƒ± mesajda ge√ßiyor mu?
                        for part in name_parts:
                            if part in last_message:
                                file_name_matches.append(part)
                
                # RAG kullanƒ±m kriterleri
                should_use_rag = False
                reason = ""
                
                # 1. Direkt PDF referansƒ±
                if any(ref in last_message for ref in direct_pdf_references):
                    should_use_rag = True
                    reason = "Direct PDF reference"
                
                # 2. Dosya ismi + i√ßerik sorusu
                elif file_name_matches and any(q in last_message for q in pdf_content_questions):
                    should_use_rag = True
                    reason = f"File name match ({file_name_matches}) + content question"
                
                # 3. PDF kelimesi + i√ßerik sorusu 
                elif ("pdf" in last_message or "dok√ºman" in last_message or "dokuman" in last_message) and \
                     any(q in last_message for q in pdf_content_questions):
                    should_use_rag = True
                    reason = "PDF keyword + content question"
                
                print(f"üéØ RAG Analysis: should_use={should_use_rag}, reason='{reason}'")
                
                if should_use_rag:
                    state["current_intent"] = "rag_search"
                    state["crew_ai_task"] = original_message
                    state["needs_crew_ai"] = False
                    print(f"‚úÖ Intent: rag_search")
                    return state
            
            # PDF mevcut deƒüilse ve PDF referansƒ± yapƒ±ldƒ±ysa uyar
            elif not has_documents and any(ref in last_message for ref in ["pdf", "dok√ºman", "dokuman", "dosya", "belge"]):
                state["current_intent"] = "no_pdf_available"
                state["needs_crew_ai"] = False
                print(f"‚úÖ Intent: no_pdf_available")
                return state
    
        # Web ara≈ütƒ±rmasƒ± otomatik algƒ±lama - SADECE kesin durumlar
        research_keywords_explicit = ["ara≈ütƒ±r", "ara≈ütƒ±rma yap", "incele", "analiz et", "web'de ara", "internette ara"]
        
        detected_intent = "general_chat"
        task_topic = original_message
        
        # A√ßƒ±k ara≈ütƒ±rma talepleri
        for keyword in research_keywords_explicit:
            if keyword in last_message:
                detected_intent = "web_research"
                task_topic = original_message.replace(keyword, "", 1).strip()
                break
        
        state["current_intent"] = detected_intent
        state["crew_ai_task"] = task_topic
        state["needs_crew_ai"] = detected_intent == "web_research"
        
        print(f"‚úÖ Final Intent: {detected_intent}")
        return state

    async def no_pdf_available_node(self, state: ConversationState) -> ConversationState:
        """PDF referansƒ± yapƒ±ldƒ± ama hi√ß PDF y√ºklenmemi≈ü"""
        
        response = ("üìÑ Bu sohbette hen√ºz herhangi bir PDF dok√ºmanƒ± y√ºklenmemi≈ü. "
                "Bir dok√ºman hakkƒ±nda soru sorabilmem i√ßin √∂nce PDF dosyanƒ±zƒ± y√ºklemeniz gerekiyor.\n\n"
                "üí° **Nasƒ±l PDF y√ºkleyebilirim?**\n"
                "‚Ä¢ Ekranƒ±n sol √ºst√ºndeki **'PDF Y√ºkle'** butonuna tƒ±klayƒ±n\n"
                "‚Ä¢ Dosyanƒ±zƒ± se√ßin ve y√ºkleme i≈ülemini bekleyin\n"
                "‚Ä¢ Y√ºkleme tamamlandƒ±ktan sonra dok√ºman i√ßeriƒüi hakkƒ±nda sorular sorabilirsiniz!\n\n"
                "üîç **PDF y√ºkledikten sonra neler yapabilirim?**\n"
                "‚Ä¢ Dok√ºmanƒ±n √∂zetini isteyebilirsiniz\n"
                "‚Ä¢ Belirli konular hakkƒ±nda sorular sorabilirsiniz\n"
                "‚Ä¢ ƒ∞√ßerikten alƒ±ntƒ±lar ve detaylar alabilirsiniz\n\n"
                f"üìù **Not:** Bu PDF'ler sadece bu sohbete ({self.chat_id}) √∂zeldir.")
        
        state["messages"].append(AIMessage(content=response))
        return state

    async def crew_research_agent_node(self, state: ConversationState) -> ConversationState:
        try:
            research_query = state['crew_ai_task']
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "crew_research_start", 
                    "message": f"ü§ñ CrewAI Asenkron Multi-Agent sistemi '{research_query}' konusunu ara≈ütƒ±rƒ±yor...", 
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }))
            
            await asyncio.sleep(0.5)
            
            research_result = await self.crew_handler.research_workflow(research_query)
            
            if research_result and not research_result.get("error"):
                state["research_data"] = research_result
                state["research_completed"] = True
                
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "crew_research_success", 
                        "message": f"‚úÖ '{research_query}' ara≈ütƒ±rmasƒ± ba≈üarƒ±yla tamamlandƒ±!", 
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id,
                        "research_data": {
                            "topic": research_result.get("topic", research_query),
                            "subtopics_count": len(research_result.get("detailed_research", [])),
                            "has_detailed_data": bool(research_result.get("detailed_research"))
                        }
                    }))
            else:
                error_msg = research_result.get("error", "Bilinmeyen ara≈ütƒ±rma hatasƒ±") if research_result else "Ara≈ütƒ±rma sonucu alƒ±namadƒ±"
                state["research_data"] = {"error": error_msg}
                
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "crew_research_error", 
                        "message": f"‚ùå Ara≈ütƒ±rma hatasƒ±: {error_msg}", 
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id
                    }))
                
        except Exception as e:
            error_msg = f"CrewAI ara≈ütƒ±rma hatasƒ±: {str(e)}"
            state["research_data"] = {"error": error_msg}
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "crew_research_error", 
                    "message": f"‚ùå {error_msg}", 
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }))
            print(f"‚ùå Crew research node error (Chat: {self.chat_id}): {e}")
            
        return state

    async def research_presentation_node(self, state: ConversationState) -> ConversationState:
        research_data = state.get("research_data", {})
        if "error" in research_data:
            response = f"√úzg√ºn√ºm, ara≈ütƒ±rma sƒ±rasƒ±nda bir hata olu≈ütu: {research_data['error']}"
        else:
            final_report = research_data.get("final_report", "")
            response = final_report if final_report else "Ara≈ütƒ±rma tamamlandƒ±, ancak bir sunum √∂zeti olu≈üturulamadƒ±."
        
        state["messages"].append(AIMessage(content=response))
        return state

    async def research_followup_node(self, state: ConversationState) -> ConversationState:
        """Ara≈ütƒ±rma tamamlandƒ±ƒüƒ±nda takip mesajƒ± g√∂nder"""
        if state.get("research_completed", False) and not "error" in state.get("research_data", {}):
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "research_completed", 
                    "message": "Ara≈ütƒ±rma ba≈üarƒ±yla tamamlandƒ±!", 
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id,
                    "research_data": state["research_data"]
                }))
            
            await asyncio.sleep(1)
            
            followup_message = ("üéØ Harika! Ara≈ütƒ±rma raporunuz hazƒ±r. Yukarƒ±daki **'Detaylƒ± Raporu G√∂r√ºnt√ºle'** butonuna "
                              "tƒ±klayarak t√ºm bulgularƒ±mƒ±zƒ± inceleyebilirsiniz.\n\n"
                              "üí° Takƒ±ldƒ±ƒüƒ±nƒ±z yerler olursa benimle birlikte raporu inceleyelim! Herhangi bir konuyu "
                              "daha detayƒ±na inmek isterseniz, sadece sorun - birlikte √ßalƒ±≈üabiliriz! ü§ù")
            
            state["messages"].append(AIMessage(content=followup_message))
        
        return state

    async def gemini_response_node(self, state: ConversationState) -> ConversationState:
        try:
            messages_for_llm = state["messages"]
            
            if state.get("has_pdf_context") and state.get("rag_context"):
                # RAG context'i kullan
                user_question = messages_for_llm[-1].content
                rag_context = state["rag_context"]
                
                contextual_prompt = f"""
Kullanƒ±cƒ±nƒ±n sorusu: {user_question}

A≈üaƒüƒ±da bu sohbette y√ºklenmi≈ü PDF dok√ºmanlarƒ±ndan bulunan ilgili bilgiler var. 
Bu bilgileri kullanarak kullanƒ±cƒ±nƒ±n sorusuna doƒüru ve detaylƒ± bir ≈üekilde cevap ver.

PDF DOK√úMANLARINDAN BULUNAN Bƒ∞LGƒ∞LER:
{rag_context}

Cevabƒ±nda:
1. PDF dok√ºmanlarƒ±ndan elde edilen bilgileri kullan
2. Hangi dok√ºmanlardan geldiƒüini belirt
3. Spesifik detaylarƒ± vurgula
4. Eƒüer PDF'lerde olmayan bir ≈üey soruyorsa, web ara≈ütƒ±rmasƒ± √∂nerebilirsin
5. Kullanƒ±cƒ± dostu ve bilgilendirici bir ton kullan

NOT: Bu bilgiler kullanƒ±cƒ±nƒ±n bu sohbete y√ºklediƒüi PDF dok√ºmanlarƒ±ndan geliyor.
Sohbet ID: {self.chat_id}
"""
                
                contextual_messages = messages_for_llm[:-1] + [HumanMessage(content=contextual_prompt)]
                response = await self.llm.ainvoke(contextual_messages)
                
            elif state.get("current_intent") == "research_question" and state.get("research_data"):
                research_context = self.format_research_context(state["research_data"])
                
                user_question = messages_for_llm[-1].content
                
                contextual_prompt = f"""
Kullanƒ±cƒ±nƒ±n sorusu: {user_question}

A≈üaƒüƒ±da CrewAI Multi-Agent sistemi ile yapƒ±lan bir ara≈ütƒ±rmanƒ±n sonu√ßlarƒ± var. 
Bu ara≈ütƒ±rma verilerini kullanarak kullanƒ±cƒ±nƒ±n sorusuna doƒüru ve detaylƒ± bir ≈üekilde cevap ver.

ARA≈ûTIRMA VERƒ∞LERƒ∞:
{research_context}

Cevabƒ±nda:
1. Ara≈ütƒ±rma verilerinden elde edilen bilgileri kullan
2. Spesifik detaylarƒ± belirt
3. Kaynaklƒ± bilgiler ver
4. Eƒüer ara≈ütƒ±rmada olmayan bir ≈üey soruyorsa, bunu belirt
5. Gerekirse daha detaylƒ± a√ßƒ±klama √∂ner

Kullanƒ±cƒ± dostu ve bilgilendirici bir ton kullan.
"""
                
                contextual_messages = messages_for_llm[:-1] + [HumanMessage(content=contextual_prompt)]
                response = await self.llm.ainvoke(contextual_messages)
                
            else:
                if messages_for_llm and "ara≈ütƒ±rma ba≈ülatƒ±lmadƒ±" in messages_for_llm[-1].content:
                    messages_for_llm = messages_for_llm[:-1]
                response = await self.llm.ainvoke(messages_for_llm)
            
            state["messages"].append(AIMessage(content=response.content))
            
        except Exception as e:
            error_message = f"√úzg√ºn√ºm, bir hata olu≈ütu: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            print(f"‚ùå Gemini response error (Chat: {self.chat_id}): {e}")
        
        return state

    def format_rag_context(self, search_results: List[dict]) -> str:
        """RAG arama sonu√ßlarƒ±nƒ± LLM i√ßin uygun formatta hazƒ±rla"""
        context = f"Y√úKLENEN PDF DOK√úMANLARINDAN BULUNAN Bƒ∞LGƒ∞LER (Sohbet: {self.chat_id}):\n\n"
        
        for i, result in enumerate(search_results, 1):
            filename = result['metadata'].get('filename', 'Bilinmeyen dosya')
            chunk_index = result['metadata'].get('chunk_index', 0)
            similarity = result.get('similarity', 0)
            content = result['content']
            
            context += f"{i}. KAYNAK: {filename} (B√∂l√ºm {chunk_index + 1}, Benzerlik: %{similarity*100:.1f})\n"
            context += f"ƒ∞√áERƒ∞K: {content}\n\n"
        
        context += f"TOPLAM KAYNAK: {len(search_results)} dok√ºman par√ßasƒ±\n"
        context += f"ARAMA TARƒ∞Hƒ∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        return context

    def format_research_context(self, research_data: dict) -> str:
        """Ara≈ütƒ±rma verilerini LLM i√ßin uygun formatta hazƒ±rla"""
        context = f"KONU: {research_data.get('topic', 'Belirtilmemi≈ü')}\n\n"
        
        detailed_research = research_data.get('detailed_research', [])
        if detailed_research:
            context += "ALT BA≈ûLIKLAR VE DETAYLAR:\n"
            for i, section in enumerate(detailed_research, 1):
                title = section.get('alt_baslik', f'Konu {i}')
                content = section.get('aciklama', 'ƒ∞√ßerik mevcut deƒüil')
                context += f"\n{i}. {title}:\n{content}\n"
        
        context += f"\nARA≈ûTIRMA TARƒ∞Hƒ∞: {research_data.get('timestamp', 'Belirtilmemi≈ü')}"
        return context
    
    async def process_user_message(self, user_message: str) -> str:
        try:
            # Kullanƒ±cƒ± mesajƒ±nƒ± conversation state'e ekle
            self.conversation_state["messages"].append(HumanMessage(content=user_message))
            self.conversation_state["websocket_callback"] = self.websocket_callback
            
            # Mesajƒ± chat manager'a kaydet
            if self.chat_manager and self.chat_id:
                self.chat_manager.save_message(self.chat_id, {
                    "type": "user",
                    "content": user_message
                })
                
                # ƒ∞lk mesajsa otomatik ba≈ülƒ±k olu≈ütur
                chat_info = self.chat_manager.get_chat_info(self.chat_id)
                if chat_info and chat_info.get("message_count", 0) == 1:
                    self.chat_manager.auto_generate_title(self.chat_id, user_message)
            
            # Graph'ƒ± √ßalƒ±≈ütƒ±r
            final_state = await self.graph.ainvoke(self.conversation_state)
            self.conversation_state = final_state
            
            # Pending action varsa mesaj d√∂nd√ºrme
            if final_state.get('pending_action'):
                return ""
            
            # AI mesajlarƒ±nƒ± al
            ai_messages = [msg for msg in final_state["messages"] if isinstance(msg, AIMessage)]
            if ai_messages:
                ai_response = ai_messages[-1].content
                
                # AI mesajƒ±nƒ± da chat manager'a kaydet
                if self.chat_manager and self.chat_id and ai_response:
                    self.chat_manager.save_message(self.chat_id, {
                        "type": "ai",
                        "content": ai_response
                    })
                
                return ai_response
            return ""
            
        except Exception as e:
            error_response = f"Bir hata olu≈ütu: {str(e)}"
            print(f"‚ùå Process message error (Chat: {self.chat_id}): {e}")
            self.conversation_state["pending_action"] = ""
            
            # Hata mesajƒ±nƒ± da kaydet
            if self.chat_manager and self.chat_id:
                self.chat_manager.save_message(self.chat_id, {
                    "type": "system",
                    "content": error_response
                })
            
            return error_response

    def get_conversation_history(self) -> List[dict]:
        """Konu≈üma ge√ßmi≈üini d√∂ner"""
        history = []
        for message in self.conversation_state["messages"]:
            if isinstance(message, HumanMessage):
                history.append({"type": "human", "content": message.content})
            elif isinstance(message, AIMessage):
                history.append({"type": "ai", "content": message.content})
        return history
    
    def get_conversation_stats(self) -> dict:
        """Konu≈üma istatistiklerini d√∂ner"""
        messages = self.conversation_state["messages"]
        user_messages = sum(1 for msg in messages if isinstance(msg, HumanMessage))
        ai_messages = sum(1 for msg in messages if isinstance(msg, AIMessage))
        
        vector_stats = self.vector_store.get_stats()
        
        return {
            "total_messages": len(messages),
            "user_messages": user_messages,
            "ai_messages": ai_messages,
            "current_intent": self.conversation_state.get("current_intent", "N/A"),
            "has_research_data": bool(self.conversation_state.get("research_data")),
            "last_research": self.conversation_state.get("research_data", {}).get("topic", ""),
            "crew_ai_enabled": True,
            "async_mode": True,
            "research_completed": self.conversation_state.get("research_completed", False),
            "rag_enabled": Config.RAG_ENABLED,
            "vector_store_stats": vector_stats,
            "chat_id": self.chat_id or "default"
        }

    def load_conversation_from_messages(self, messages: List[dict]):
        """Daha √∂nce kaydedilmi≈ü mesajlarƒ± y√ºkle"""
        try:
            # SystemMessage'ƒ± koru, diƒüerlerini temizle
            system_messages = [msg for msg in self.conversation_state["messages"] if isinstance(msg, SystemMessage)]
            self.conversation_state["messages"] = system_messages
            
            # Kaydedilmi≈ü mesajlarƒ± ekle
            for msg in messages:
                if msg.get("type") == "user":
                    self.conversation_state["messages"].append(HumanMessage(content=msg["content"]))
                elif msg.get("type") == "ai":
                    self.conversation_state["messages"].append(AIMessage(content=msg["content"]))
                    
        except Exception as e:
            print(f"‚ùå Load conversation error (Chat: {self.chat_id}): {e}")

    def reset_conversation(self):
        """Konu≈ümayƒ± sƒ±fƒ±rla"""
        self.conversation_state = ConversationState(
            messages=[SystemMessage(content=Config.SYSTEM_PROMPT)],
            current_intent="",
            needs_crew_ai=False,
            crew_ai_task="",
            user_context={},
            conversation_summary="",
            research_data={},
            websocket_callback=self.websocket_callback,
            pending_action="",
            research_completed=False,
            rag_context="",
            has_pdf_context=False,
            chat_id=self.chat_id or "",
            chat_manager=self.chat_manager
        )

    def update_chat_manager(self, chat_manager):
        """Chat manager referansƒ±nƒ± g√ºncelle"""
        self.chat_manager = chat_manager
        self.conversation_state["chat_manager"] = chat_manager

    def get_chat_id(self) -> str:
        """Mevcut chat ID'yi d√∂ner"""
        return self.chat_id or ""

    def set_chat_id(self, chat_id: str):
        """Chat ID'yi g√ºncelle ve vector store'u yeniden ba≈ülat"""
        self.chat_id = chat_id
        self.conversation_state["chat_id"] = chat_id
        
        # Vector store'u yeni chat ID ile yeniden ba≈ülat
        self.vector_store = VectorStore(Config.VECTOR_STORE_PATH, chat_id=chat_id)