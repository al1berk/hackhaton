# src/core/conversation.py

from typing import TypedDict, List, Literal
from chromadb import logger
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
import asyncio
import json
from datetime import datetime
import re

from .config import Config
from agents.research_crew import AsyncCrewAIA2AHandler
from agents.crew_agents import CrewAISystem # YENÄ°: CrewAI sistemini import et

from core.vector_store import VectorStore

class ConversationState(TypedDict):
    messages: List[BaseMessage]
    current_intent: str
    needs_crew_ai: bool
    crew_ai_task: str
    user_context: dict
    conversation_summary: str
    research_data: dict
    websocket_callback: object
    pending_action: str
    research_completed: bool
    rag_context: str
    has_pdf_context: bool
    chat_id: str
    chat_manager: object  # Chat manager referansÄ±
    test_generation_requested: bool
    test_parameters: dict
    generated_questions: dict
    full_document_text: str # DÃ¶kÃ¼manÄ±n tam metnini tutmak iÃ§in
    # DÃœZELTÄ°LMÄ°Å TEST ALANLARI
    awaiting_test_params: bool
    test_param_stage: str  # "start", "question_types", "difficulty", "student_level", "complete"
    partial_test_params: dict
    test_params_ready: bool  # Test parametrelerinin hazÄ±r olup olmadÄ±ÄŸÄ±nÄ± belirler
    ui_message_sent: bool  # UI mesajÄ±nÄ±n gÃ¶nderilip gÃ¶nderilmediÄŸini takip eder - YENÄ°
    
class AsyncLangGraphDialog:
    def __init__(self, websocket_callback=None, chat_id=None, chat_manager=None):
        self.llm = ChatGoogleGenerativeAI(
            model=Config.GEMINI_MODEL,
            google_api_key=Config.GOOGLE_API_KEY,
            temperature=Config.GEMINI_TEMPERATURE,
        )
        
        self.websocket_callback = websocket_callback
        self.chat_id = chat_id
        self.chat_manager = chat_manager
        self.crew_handler = AsyncCrewAIA2AHandler(websocket_callback)
        self.test_crew = CrewAISystem(api_key=Config.GOOGLE_API_KEY, websocket_callback=websocket_callback)

        
        # Chat-specific vector store oluÅŸtur
        self.vector_store = VectorStore(Config.VECTOR_STORE_PATH, chat_id=chat_id)
        
        self.graph = self.create_conversation_graph()
        
        self.conversation_state = ConversationState(
            messages=[SystemMessage(content=Config.SYSTEM_PROMPT)],
            current_intent="",
            needs_crew_ai=False,
            crew_ai_task="",
            user_context={},
            conversation_summary="",
            research_data={},
            websocket_callback=websocket_callback,
            pending_action="",
            research_completed=False,
            rag_context="",
            has_pdf_context=False,
            chat_id=chat_id or "",
            chat_manager=chat_manager,
            test_generation_requested=False,
            test_parameters={},
            generated_questions={},
            full_document_text="",
            awaiting_test_params=False,
            test_param_stage="start",
            partial_test_params={},
            test_params_ready=False,
            ui_message_sent=False  # YENÄ°: UI mesaj takibi
        )
    
    def create_conversation_graph(self):
        workflow = StateGraph(ConversationState)
        
        # DÃ¼ÄŸÃ¼mleri tanÄ±mla
        workflow.add_node("intent_analysis", self.intent_analysis_node)
        workflow.add_node("rag_search", self.rag_search_node)
        workflow.add_node("no_pdf_available", self.no_pdf_available_node)
        workflow.add_node("crew_research_agent", self.crew_research_agent_node)
        workflow.add_node("research_presentation", self.research_presentation_node)
        workflow.add_node("gemini_response", self.gemini_response_node)
        workflow.add_node("check_document_for_test", self.check_document_for_test_node)
        workflow.add_node("ask_test_parameters", self.ask_test_parameters_node)
        workflow.add_node("process_test_parameters", self.process_test_parameters_node)
        workflow.add_node("generate_test_questions", self.generate_test_questions_node)
        workflow.add_node("present_test_results", self.present_test_results_node)
        
        # GiriÅŸ noktasÄ±nÄ± belirle
        workflow.set_entry_point("intent_analysis")
        
        # Intent analysis'ten sonraki yÃ¶nlendirmeler
        workflow.add_conditional_edges(
            "intent_analysis",
            self.route_intent,
            {
                "web_research": "crew_research_agent",
                "rag_search": "rag_search",
                "no_pdf_available": "no_pdf_available",
                "generate_test": "check_document_for_test",
                "process_test_params": "process_test_parameters",
                "gemini": "gemini_response"
            }
        )

        # Test kontrolÃ¼ sonrasÄ± yÃ¶nlendirmeler
        workflow.add_conditional_edges(
            "check_document_for_test",
            self.route_test_document_check,
            {
                "ask_test_parameters": "ask_test_parameters",
                "gemini_response": "gemini_response"
            }
        )
        
        # Test parametreleri iÅŸleme sonrasÄ±
        workflow.add_conditional_edges(
            "process_test_parameters",
            self.route_test_parameters,
            {
                "ask_test_parameters": "ask_test_parameters",
                "generate_test_questions": "generate_test_questions",
                "gemini_response": "gemini_response"
            }
        )
        
        # Test parametreleri alma sonrasÄ±
        workflow.add_edge("ask_test_parameters", END)
        
        # DiÄŸer baÄŸlantÄ±lar
        workflow.add_edge("rag_search", "gemini_response")
        workflow.add_edge("no_pdf_available", END)
        workflow.add_edge("crew_research_agent", "research_presentation")
        workflow.add_edge("research_presentation", END)
        workflow.add_edge("generate_test_questions", "present_test_results")
        workflow.add_edge("present_test_results", END)
        workflow.add_edge("gemini_response", END)

        return workflow.compile()

    def route_intent(self, state: ConversationState) -> str:
        """Intent'e gÃ¶re yÃ¶nlendirme - DÃœZELTÄ°LMÄ°Å"""
        intent = state.get("current_intent", "gemini")
        
        # EÄŸer test parametreleri iÅŸlenmeyi bekliyorsa
        if state.get("awaiting_test_params") and intent != "generate_test":
            return "process_test_params"
        
        if intent in ["web_research", "rag_search", "no_pdf_available", "generate_test", "process_test_params"]:
            return intent
        return "gemini"

    def route_test_document_check(self, state: ConversationState) -> str:
        """Test iÃ§in dokÃ¼man kontrolÃ¼ sonrasÄ± yÃ¶nlendirme"""
        if state.get("full_document_text"):
            return "ask_test_parameters"
        return "gemini_response"
    
    def route_test_parameters(self, state: ConversationState) -> str:
        """Test parametrelerini iÅŸleme sonrasÄ± yÃ¶nlendirme"""
        if state.get("test_params_ready"):
            return "generate_test_questions"
        elif state.get("awaiting_test_params"):
            return "ask_test_parameters"
        return "gemini_response"

    async def rag_search_node(self, state: ConversationState):
        """PDF dokÃ¼manlarÄ±nda arama yapar"""
        try:
            last_message = state["messages"][-1].content
            
            # VektÃ¶r deposunda ara
            search_results = self.vector_store.search_similar(
                query=last_message,
                n_results=Config.RAG_TOP_K
            )
            
            if search_results:
                # Benzerlik skoruna gÃ¶re filtrele
                relevant_results = [
                    result for result in search_results 
                    if result['similarity'] >= Config.RAG_SIMILARITY_THRESHOLD
                ]
                
                if relevant_results:
                    # RAG context'i oluÅŸtur
                    rag_context = self.format_rag_context(relevant_results)
                    state["rag_context"] = rag_context
                    state["has_pdf_context"] = True
                    
                    if self.websocket_callback:
                        await self.websocket_callback(json.dumps({
                            "type": "rag_found",
                            "message": f"ğŸ“š {len(relevant_results)} ilgili dokÃ¼man parÃ§asÄ± bulundu (Sohbet: {self.chat_id})",
                            "timestamp": datetime.utcnow().isoformat(),
                            "chat_id": self.chat_id
                        }))
                else:
                    state["rag_context"] = ""
                    state["has_pdf_context"] = False
            else:
                state["rag_context"] = ""
                state["has_pdf_context"] = False
                
        except Exception as e:
            print(f"âŒ RAG search error (Chat: {self.chat_id}): {e}")
            state["rag_context"] = ""
            state["has_pdf_context"] = False
        
        # KRÄ°TÄ°K DÃœZELTME: State'i return et!
        return state
    
    def format_rag_context(self, search_results: List[dict]) -> str:
        """RAG arama sonuÃ§larÄ±nÄ± LLM iÃ§in uygun formatta hazÄ±rla"""
        context = f"===== YÃœKLENEN PDF DOKÃœMANLARINDAN BULUNAN BÄ°LGÄ°LER =====\n"
        context += f"Sohbet ID: {self.chat_id}\n"
        context += f"Bulunan parÃ§a sayÄ±sÄ±: {len(search_results)}\n\n"
        
        for i, result in enumerate(search_results, 1):
            filename = result['metadata'].get('filename', 'Bilinmeyen dosya')
            chunk_index = result['metadata'].get('chunk_index', 0)
            similarity = result.get('similarity', 0)
            content = result['content']
            
            context += f"KAYNAK {i}:\n"
            context += f"ğŸ“„ Dosya: {filename}\n"
            context += f"ğŸ“ BÃ¶lÃ¼m: {chunk_index + 1}\n"
            context += f"ğŸ¯ Benzerlik: %{similarity*100:.1f}\n"
            context += f"ğŸ“ Ä°Ã‡ERÄ°K:\n{content}\n"
            context += f"{'='*50}\n\n"
        
        context += f"Ã–NEMLÄ°: Bu bilgiler kullanÄ±cÄ±nÄ±n bu sohbete yÃ¼klediÄŸi PDF dokÃ¼manlarÄ±ndan geliyor.\n"
        context += f"KullanÄ±cÄ±nÄ±n sorusunu bu PDF iÃ§eriÄŸine dayanarak yanÄ±tla.\n"
        context += f"Arama tarihi: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        context += "=" * 60
        
        return context

    def format_research_context(self, research_data: dict) -> str:
        """AraÅŸtÄ±rma verilerini LLM iÃ§in uygun formatta hazÄ±rla"""
        context = f"KONU: {research_data.get('topic', 'BelirtilmemiÅŸ')}\n\n"
        
        detailed_research = research_data.get('detailed_research', [])
        if detailed_research:
            context += "ALT BAÅLIKLAR VE DETAYLAR:\n"
            for i, section in enumerate(detailed_research, 1):
                title = section.get('alt_baslik', f'Konu {i}')
                content = section.get('aciklama', 'Ä°Ã§erik mevcut deÄŸil')
                context += f"\n{i}. {title}:\n{content}\n"
        
        context += f"\nARAÅTIRMA TARÄ°HÄ°: {research_data.get('timestamp', 'BelirtilmemiÅŸ')}"
        return context
    
    async def process_user_message(self, user_message: str) -> str:
        try:
            # KullanÄ±cÄ± mesajÄ±nÄ± conversation state'e ekle
            self.conversation_state["messages"].append(HumanMessage(content=user_message))
            self.conversation_state["websocket_callback"] = self.websocket_callback
            
            # MesajÄ± chat manager'a kaydet
            if self.chat_manager and self.chat_id:
                self.chat_manager.save_message(self.chat_id, {
                    "type": "user",
                    "content": user_message
                })
                
                # Ä°lk mesajsa otomatik baÅŸlÄ±k oluÅŸtur
                chat_info = self.chat_manager.get_chat_info(self.chat_id)
                if chat_info and chat_info.get("message_count", 0) == 1:
                    self.chat_manager.auto_generate_title(self.chat_id, user_message)
            
            # Graph'Ä± Ã§alÄ±ÅŸtÄ±r
            final_state = await self.graph.ainvoke(self.conversation_state)
            self.conversation_state = final_state
            
            # Pending action varsa mesaj dÃ¶ndÃ¼rme
            if final_state.get('pending_action'):
                return ""
            
            # AI mesajlarÄ±nÄ± al
            ai_messages = [msg for msg in final_state["messages"] if isinstance(msg, AIMessage)]
            if ai_messages:
                ai_response = ai_messages[-1].content
                
                # AI mesajÄ±nÄ± da chat manager'a kaydet
                if self.chat_manager and self.chat_id and ai_response:
                    self.chat_manager.save_message(self.chat_id, {
                        "type": "ai",
                        "content": ai_response
                    })
                
                return ai_response
            return ""
            
        except Exception as e:
            error_response = f"Bir hata oluÅŸtu: {str(e)}"
            print(f"âŒ Process message error (Chat: {self.chat_id}): {e}")
            self.conversation_state["pending_action"] = ""
            
            # Hata mesajÄ±nÄ± da kaydet
            if self.chat_manager and self.chat_id:
                self.chat_manager.save_message(self.chat_id, {
                    "type": "system",
                    "content": error_response
                })
            
            return error_response

    def get_conversation_history(self) -> List[dict]:
        """KonuÅŸma geÃ§miÅŸini dÃ¶ner"""
        history = []
        for message in self.conversation_state["messages"]:
            if isinstance(message, HumanMessage):
                history.append({"type": "human", "content": message.content})
            elif isinstance(message, AIMessage):
                history.append({"type": "ai", "content": message.content})
        return history
    
    def get_conversation_stats(self) -> dict:
        """KonuÅŸma istatistiklerini dÃ¶ner"""
        messages = self.conversation_state["messages"]
        user_messages = sum(1 for msg in messages if isinstance(msg, HumanMessage))
        ai_messages = sum(1 for msg in messages if isinstance(msg, AIMessage))
        
        vector_stats = self.vector_store.get_stats()
        
        return {
            "total_messages": len(messages),
            "user_messages": user_messages,
            "ai_messages": ai_messages,
            "current_intent": self.conversation_state.get("current_intent", "N/A"),
            "has_research_data": bool(self.conversation_state.get("research_data")),
            "last_research": self.conversation_state.get("research_data", {}).get("topic", ""),
            "crew_ai_enabled": True,
            "async_mode": True,
            "research_completed": self.conversation_state.get("research_completed", False),
            "rag_enabled": Config.RAG_ENABLED,
            "vector_store_stats": vector_stats,
            "chat_id": self.chat_id or "default",
            # Test durumu istatistikleri - DÃœZELTÄ°LMÄ°Å
            "test_stats": {
                "awaiting_params": self.conversation_state.get("awaiting_test_params", False),
                "param_stage": self.conversation_state.get("test_param_stage", "start"),
                "params_ready": self.conversation_state.get("test_params_ready", False),
                "has_generated_test": bool(self.conversation_state.get("generated_questions")),
                "ui_message_sent": self.conversation_state.get("ui_message_sent", False)
            }
        }

    def load_conversation_from_messages(self, messages: List[dict]):
        """Daha Ã¶nce kaydedilmiÅŸ mesajlarÄ± yÃ¼kle"""
        try:
            # SystemMessage'Ä± koru, diÄŸerlerini temizle
            system_messages = [msg for msg in self.conversation_state["messages"] if isinstance(msg, SystemMessage)]
            self.conversation_state["messages"] = system_messages
            
            # KaydedilmiÅŸ mesajlarÄ± ekle
            for msg in messages:
                if msg.get("type") == "user":
                    self.conversation_state["messages"].append(HumanMessage(content=msg["content"]))
                elif msg.get("type") == "ai":
                    self.conversation_state["messages"].append(AIMessage(content=msg["content"]))
                    
        except Exception as e:
            print(f"âŒ Load conversation error (Chat: {self.chat_id}): {e}")

    def reset_conversation(self):
        """KonuÅŸmayÄ± sÄ±fÄ±rla"""
        self.conversation_state = ConversationState(
            messages=[SystemMessage(content=Config.SYSTEM_PROMPT)],
            current_intent="",
            needs_crew_ai=False,
            crew_ai_task="",
            user_context={},
            conversation_summary="",
            research_data={},
            websocket_callback=self.websocket_callback,
            pending_action="",
            research_completed=False,
            rag_context="",
            has_pdf_context=False,
            chat_id=self.chat_id or "",
            chat_manager=self.chat_manager,
            test_generation_requested=False,
            test_parameters={},
            generated_questions={},
            full_document_text="",
            awaiting_test_params=False,
            test_param_stage="start",
            partial_test_params={},
            test_params_ready=False,
            ui_message_sent=False  # YENÄ°: UI mesaj takibi sÄ±fÄ±rla
        )

    def update_chat_manager(self, chat_manager):
        """Chat manager referansÄ±nÄ± gÃ¼ncelle"""
        self.chat_manager = chat_manager
        self.conversation_state["chat_manager"] = chat_manager

    def get_chat_id(self) -> str:
        """Mevcut chat ID'yi dÃ¶ner"""
        return self.chat_id or ""

    def set_chat_id(self, chat_id: str):
        """Chat ID'yi gÃ¼ncelle ve vector store'u yeniden baÅŸlat"""
        self.chat_id = chat_id
        self.conversation_state["chat_id"] = chat_id
        
        # Vector store'u yeni chat ID ile yeniden baÅŸlat
        self.vector_store = VectorStore(Config.VECTOR_STORE_PATH, chat_id=chat_id)
    
    def intent_analysis_node(self, state: ConversationState) -> ConversationState:
        last_message = state["messages"][-1].content.strip().lower()
        original_message = state["messages"][-1].content.strip()
        
        # Force web research flag'ini kontrol et
        force_web_research = state.get("force_web_research", False)
        
        print(f"ğŸ” Intent Analysis - Message: '{last_message[:50]}...', Force Web Research: {force_web_research}")
        
        # Ã–NCE test parametresi bekleme durumunu kontrol et
        if state.get("awaiting_test_params"):
            # Test parametresi bekleniyor
            state["current_intent"] = "process_test_params"
            logger.info("âœ… Intent detected: process_test_params (awaiting parameters)")
            return state
        
        # Test oluÅŸturma komutlarÄ± - GENÄ°ÅLETÄ°LMÄ°Å LÄ°STE
        test_keywords = [
            "test oluÅŸtur", "test olustur", "soru hazÄ±rla", "sÄ±nav yap", "test yap", 
            "soru Ã¼ret", "soru uret", "test hazÄ±rla", "quiz oluÅŸtur",
            "quiz olustur", "sÄ±nav oluÅŸtur", "sinav olustur", "test Ã¼ret", "test uret",
            "sorular oluÅŸtur", "sorular olustur", "deÄŸerlendirme yap", "degerlendirme yap"
        ]
        
        if any(keyword in last_message for keyword in test_keywords):
            state["current_intent"] = "generate_test"
            state["test_generation_requested"] = True
            logger.info("âœ… Intent detected: generate_test")
            return state

        # AraÅŸtÄ±rma tamamlandÄ±ysa ve research data varsa
        if state.get("research_completed", False) and state.get("research_data"):
            research_keywords = ["araÅŸtÄ±rma", "rapor", "bulgu", "sonuÃ§", "detay", "aÃ§Ä±kla", "anlatÄ±r mÄ±sÄ±n", 
                            "nedir", "nasÄ±l", "ne demek", "anlat", "aÃ§Ä±klayabilir", "daha fazla bilgi"]
            
            if any(keyword in last_message for keyword in research_keywords):
                state["current_intent"] = "research_question"
                state["needs_crew_ai"] = False
                print(f"âœ… Intent: research_question")
                return state
        
        # Ã–NCE web araÅŸtÄ±rmasÄ± flag'ini kontrol et
        if force_web_research:
            state["current_intent"] = "web_research"
            state["crew_ai_task"] = original_message
            state["needs_crew_ai"] = True
            print(f"âœ… Intent: web_research (forced)")
            return state
        
        # RAG kontrolÃ¼ - DAHA SPESIFIK KRITERLER
        if Config.RAG_ENABLED:
            vector_stats = self.vector_store.get_stats()
            has_documents = vector_stats.get("total_documents", 0) > 0
            print(f"ğŸ“š PDF Documents: {has_documents}, Total: {vector_stats.get('total_documents', 0)}")
            
            if has_documents:
                # Direkt PDF referanslarÄ±
                direct_pdf_references = [
                    "bu dokÃ¼man", "bu dokuman", "bu dosya", "bu pdf", "bu rapor",
                    "bu belge", "yÃ¼klediÄŸim", "yukledÄ±gÄ±m", "gÃ¶nderdiÄŸim", "gonderdigim",
                    "dokÃ¼manÄ±", "dokumanÄ±", "dosyayÄ±", "pdf'i", "raporu", "belgeyi",
                    "dosyada", "dosyadan", "pdf'te", "pdf'de", "belgede", "dÃ¶kÃ¼manÄ±", "dokumanÄ±"
                ]
                
                # PDF iÃ§erik sorularÄ±
                pdf_content_questions = [
                    "Ã¶zet", "Ã¶zetle", "iÃ§erik", "iÃ§inde", "neler var", "ne diyor",
                    "bahsediyor", "yaziyor", "yazÄ±yor", "anlatÄ±yor", "gÃ¶steriyor",
                    "aÃ§Ä±klÄ±yor", "hangi konular", "nasÄ±l aÃ§Ä±klÄ±yor", "konu baÅŸlÄ±klarÄ±",
                    "baÅŸlÄ±klar", "konular", "bÃ¶lÃ¼mler", "detaylar", "bilgiler", "iÃ§indekiler"
                ]
                
                # Dosya ismi referanslarÄ±
                uploaded_files = vector_stats.get("documents", [])
                file_name_matches = []
                for doc in uploaded_files:
                    filename = doc.get("filename", "").lower()
                    if filename:
                        # Dosya adÄ±nÄ±n ana kÄ±smÄ±nÄ± al (uzantÄ±sÄ±z)
                        name_without_ext = filename.replace(".pdf", "").replace("-", " ").replace("_", " ")
                        name_parts = [part for part in name_without_ext.split() if len(part) > 3]
                        
                        # Bu dosya isminin parÃ§alarÄ± mesajda geÃ§iyor mu?
                        for part in name_parts:
                            if part in last_message:
                                file_name_matches.append(part)
                
                # RAG kullanÄ±m kriterleri
                should_use_rag = False
                reason = ""
                
                # 1. Direkt PDF referansÄ±
                if any(ref in last_message for ref in direct_pdf_references):
                    should_use_rag = True
                    reason = "Direct PDF reference"
                
                # 2. **KONU BAÅLIÄI SORGUSU - GÃœÃ‡LENDÄ°RÄ°LMÄ°Å**
                elif any(kw in last_message for kw in ["konu baÅŸlÄ±klarÄ±", "baÅŸlÄ±klar", "konular", "bÃ¶lÃ¼mler", "iÃ§indekiler", "pdf deki", "pdfdeki", "pdf in", "pdfin", "baÅŸlÄ±k", "konu", "iÃ§erik"]):
                    should_use_rag = True
                    reason = "Table of contents/content request"
                
                # 3. Dosya ismi + iÃ§erik sorusu
                elif file_name_matches and any(q in last_message for q in pdf_content_questions):
                    should_use_rag = True
                    reason = f"File name match ({file_name_matches}) + content question"
                
                # 4. PDF kelimesi + iÃ§erik sorusu 
                elif ("pdf" in last_message or "dokÃ¼man" in last_message or "dokuman" in last_message) and \
                     any(q in last_message for q in pdf_content_questions):
                    should_use_rag = True
                    reason = "PDF keyword + content question"
                
                print(f"ğŸ¯ RAG Analysis: should_use={should_use_rag}, reason='{reason}'")
                
                if should_use_rag:
                    state["current_intent"] = "rag_search"
                    state["crew_ai_task"] = original_message
                    state["needs_crew_ai"] = False
                    print(f"âœ… Intent: rag_search")
                    return state
            
            # PDF mevcut deÄŸilse ve PDF referansÄ± yapÄ±ldÄ±ysa uyar
            elif not has_documents and any(ref in last_message for ref in ["pdf", "dokÃ¼man", "dokuman", "dosya", "belge"]):
                state["current_intent"] = "no_pdf_available"
                state["needs_crew_ai"] = False
                print(f"âœ… Intent: no_pdf_available")
                return state
    
        # Web araÅŸtÄ±rmasÄ± otomatik algÄ±lama - SADECE kesin durumlar
        research_keywords_explicit = ["araÅŸtÄ±r", "araÅŸtÄ±rma yap", "incele", "analiz et", "web'de ara", "internette ara"]
        
        detected_intent = "gemini"  # VarsayÄ±lan olarak gemini response
        task_topic = original_message
        
        # AÃ§Ä±k araÅŸtÄ±rma talepleri
        for keyword in research_keywords_explicit:
            if keyword in last_message:
                detected_intent = "web_research"
                task_topic = original_message.replace(keyword, "", 1).strip()
                break
        
        state["current_intent"] = detected_intent
        state["crew_ai_task"] = task_topic
        state["needs_crew_ai"] = detected_intent == "web_research"
        
        print(f"âœ… Final Intent: {detected_intent}")
        return state

    async def no_pdf_available_node(self, state: ConversationState) -> ConversationState:
        """PDF referansÄ± yapÄ±ldÄ± ama hiÃ§ PDF yÃ¼klenmemiÅŸ"""
        
        response = ("ğŸ“„ Bu sohbette henÃ¼z herhangi bir PDF dokÃ¼manÄ± yÃ¼klenmemiÅŸ. "
                "Bir dokÃ¼man hakkÄ±nda soru sorabilmem iÃ§in Ã¶nce PDF dosyanÄ±zÄ± yÃ¼klemeniz gerekiyor.\n\n"
                "ğŸ’¡ **NasÄ±l PDF yÃ¼kleyebilirim?**\n"
                "â€¢ EkranÄ±n sol Ã¼stÃ¼ndeki **'PDF YÃ¼kle'** butonuna tÄ±klayÄ±n\n"
                "â€¢ DosyanÄ±zÄ± seÃ§in ve yÃ¼kleme iÅŸlemini bekleyin\n"
                "â€¢ YÃ¼kleme tamamlandÄ±ktan sonra dokÃ¼man iÃ§eriÄŸi hakkÄ±nda sorular sorabilirsiniz!\n\n"
                "ğŸ” **PDF yÃ¼kledikten sonra neler yapabilirim?**\n"
                "â€¢ DokÃ¼manÄ±n Ã¶zetini isteyebilirsiniz\n"
                "â€¢ Belirli konular hakkÄ±nda sorular sorabilirsiniz\n"
                "â€¢ Ä°Ã§erikten alÄ±ntÄ±lar ve detaylar alabilirsiniz\n\n"
                f"ğŸ“ **Not:** Bu PDF'ler sadece bu sohbete ({self.chat_id}) Ã¶zeldir.")
        
        state["messages"].append(AIMessage(content=response))
        return state

    async def crew_research_agent_node(self, state: ConversationState) -> ConversationState:
        try:
            research_query = state['crew_ai_task']
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "crew_research_start", 
                    "message": f"ğŸ¤– CrewAI Asenkron Multi-Agent sistemi '{research_query}' konusunu araÅŸtÄ±rÄ±yor...", 
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }))
            
            await asyncio.sleep(0.5)
            
            research_result = await self.crew_handler.research_workflow(research_query)
            
            if research_result and not research_result.get("error"):
                state["research_data"] = research_result
                state["research_completed"] = True
                
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "crew_research_success", 
                        "message": f"âœ… '{research_query}' araÅŸtÄ±rmasÄ± baÅŸarÄ±yla tamamlandÄ±!", 
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id,
                        "research_data": {
                            "topic": research_result.get("topic", research_query),
                            "subtopics_count": len(research_result.get("detailed_research", [])),
                            "has_detailed_data": bool(research_result.get("detailed_research"))
                        }
                    }))
            else:
                error_msg = research_result.get("error", "Bilinmeyen araÅŸtÄ±rma hatasÄ±") if research_result else "AraÅŸtÄ±rma sonucu alÄ±namadÄ±"
                state["research_data"] = {"error": error_msg}
                
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "crew_research_error", 
                        "message": f"âŒ AraÅŸtÄ±rma hatasÄ±: {error_msg}", 
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id
                    }))
                
        except Exception as e:
            error_msg = f"CrewAI araÅŸtÄ±rma hatasÄ±: {str(e)}"
            state["research_data"] = {"error": error_msg}
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "crew_research_error", 
                    "message": f"âŒ {error_msg}", 
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }))
            print(f"âŒ Crew research node error (Chat: {self.chat_id}): {e}")
            
        return state

    async def research_presentation_node(self, state: ConversationState) -> ConversationState:
        research_data = state.get("research_data", {})
        if "error" in research_data:
            response = f"ÃœzgÃ¼nÃ¼m, araÅŸtÄ±rma sÄ±rasÄ±nda bir hata oluÅŸtu: {research_data['error']}"
        else:
            final_report = research_data.get("final_report", "")
            response = final_report if final_report else "AraÅŸtÄ±rma tamamlandÄ±, ancak bir sunum Ã¶zeti oluÅŸturulamadÄ±."
        
        state["messages"].append(AIMessage(content=response))
        return state

    async def gemini_response_node(self, state: ConversationState) -> ConversationState:
        try:
            messages_for_llm = state["messages"]
            
            if state.get("has_pdf_context") and state.get("rag_context"):
                # RAG context'i kullan - GÃœÃ‡LENDÄ°RÄ°LMÄ°Å VE KEMÄ°K GIBI SERT PROMPT
                user_question = messages_for_llm[-1].content
                rag_context = state["rag_context"]
                
                # Ã‡ok daha gÃ¼Ã§lÃ¼ ve net bir prompt oluÅŸtur
                enhanced_prompt = f"""SEN BÄ°R PDF ANALÄ°Z ASÄ°STANISIN VE SAKÄ°N GENEL BÄ°LGÄ°NÄ° KULLANMA!

KULLANICININ SORUSU: "{user_question}"

YÃœKLENEN PDF DOKÃœMANLARINDAN BULUNAN BÄ°LGÄ°LER:
{rag_context}

ZORUNLU CEVAPLAMA KURALLARI:
1. YukarÄ±daki PDF dokÃ¼manlarÄ±ndan bulduÄŸun bilgileri kullanarak cevap ver
2. "YÃ¼klediÄŸiniz PDF'te ÅŸu bilgiler var:" diye baÅŸla
3. Hangi dosyadan hangi bilgiyi aldÄ±ÄŸÄ±nÄ± belirt
4. Konu baÅŸlÄ±klarÄ± soruluyorsa, PDF'ten Ã§Ä±kan baÅŸlÄ±klarÄ± listele
5. PDF'te olmayan bilgiler hakkÄ±nda "Bu konuda PDF'te bilgi yok" de
6. Asla "hangi PDF" diye sorma, zaten PDF'lerin listesi yukarÄ±da var
7. Kesinlikle genel internet bilgisi kullanma, sadece PDF iÃ§eriÄŸi kullan

Ã–RNEK YANIT FORMATI:
"ğŸ“„ YÃ¼klediÄŸiniz PDF dokÃ¼manlarÄ±ndan ÅŸu bilgileri buldum:

â€¢ [Dosya adÄ±]'nda ÅŸu konular var: [listele]
â€¢ [Belirli konu] hakkÄ±nda: [PDF'ten alÄ±ntÄ±]

Kaynak: [Dosya adÄ±], BÃ¶lÃ¼m [X]"

ÅÄ°MDÄ° BU KURALLARA UYARAK CEVAP VER:"""
                
                # Sadece system message + yeni prompt gÃ¶nder
                contextual_messages = [
                    SystemMessage(content="Sen PDF analiz asistanÄ±sÄ±n. Sadece yÃ¼klenen dokÃ¼manlardan bilgi ver."),
                    HumanMessage(content=enhanced_prompt)
                ]
                
                response = await self.llm.ainvoke(contextual_messages)
                
            elif state.get("current_intent") == "research_question" and state.get("research_data"):
                research_context = self.format_research_context(state["research_data"])
                
                user_question = messages_for_llm[-1].content
                
                contextual_prompt = f"""
KullanÄ±cÄ±nÄ±n sorusu: {user_question}

AÅŸaÄŸÄ±da CrewAI Multi-Agent sistemi ile yapÄ±lan bir araÅŸtÄ±rmanÄ±n sonuÃ§larÄ± var. 
Bu araÅŸtÄ±rma verilerini kullanarak kullanÄ±cÄ±nÄ±n sorusuna doÄŸru ve detaylÄ± bir ÅŸekilde cevap ver.

ARAÅTIRMA VERÄ°LERÄ°:
{research_context}

CevabÄ±nda:
1. AraÅŸtÄ±rma verilerinden elde edilen bilgileri kullan
2. Spesifik detaylarÄ± belirt
3. KaynaklÄ± bilgiler ver
4. EÄŸer araÅŸtÄ±rmada olmayan bir ÅŸey soruyorsa, bunu belirt
5. Gerekirse daha detaylÄ± aÃ§Ä±klama Ã¶ner

KullanÄ±cÄ± dostu ve bilgilendirici bir ton kullan.
"""
                
                contextual_messages = messages_for_llm[:-1] + [HumanMessage(content=contextual_prompt)]
                response = await self.llm.ainvoke(contextual_messages)
                
            else:
                # Normal Gemini response
                if messages_for_llm and "araÅŸtÄ±rma baÅŸlatÄ±lmadÄ±" in messages_for_llm[-1].content:
                    messages_for_llm = messages_for_llm[:-1]
                response = await self.llm.ainvoke(messages_for_llm)
            
            state["messages"].append(AIMessage(content=response.content))
            
        except Exception as e:
            error_message = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            print(f"âŒ Gemini response error (Chat: {self.chat_id}): {e}")
        
        return state
    
    def _get_full_text_from_vector_store(self) -> str:
        """VektÃ¶r veritabanÄ±ndaki tÃ¼m parÃ§alarÄ± birleÅŸtirerek tam metni alÄ±r."""
        try:
            all_docs = self.vector_store.collection.get(include=["documents"])
            if not all_docs or not all_docs.get('documents'):
                return ""
            full_text = "\n\n".join(all_docs['documents'])
            logger.info(f"ğŸ“„ VektÃ¶r deposundan {len(full_text)} karakterlik tam metin alÄ±ndÄ±.")
            return full_text
        except Exception as e:
            logger.error(f"âŒ VektÃ¶r deposundan tam metin alÄ±namadÄ±: {e}")
            return ""

    async def check_document_for_test_node(self, state: ConversationState) -> ConversationState:
        """Test Ã¼retimi iÃ§in dÃ¶kÃ¼man olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
        logger.info("STEP: Checking for document to generate test...")
        
        # Chat ID'yi kullanarak vektÃ¶r deposunda arama yap
        chat_id = state.get("chat_id") or self.chat_id
        if not chat_id:
            logger.warning("Chat ID bulunamadÄ±, test Ã¼retimi yapÄ±lamaz.")
            state["messages"].append(AIMessage(content="ÃœzgÃ¼nÃ¼m, chat oturumu bulunamadÄ±. LÃ¼tfen sayfayÄ± yenileyin."))
            state["full_document_text"] = ""
            return state
        
        # VektÃ¶r deposundan tam metni al
        full_text = self._get_full_text_from_vector_store()
        
        if not full_text:
            # Vector store boÅŸsa, kullanÄ±cÄ±ya dokÃ¼man yÃ¼klemesini sÃ¶yle
            logger.warning(f"Chat {chat_id} iÃ§in hiÃ§ dokÃ¼man bulunamadÄ±.")
            
            # Vector store stats'Ä±nÄ± kontrol et
            vector_stats = self.vector_store.get_stats()
            logger.info(f"Vector store stats: {vector_stats}")
            
            error_message = ("ğŸ“š Test oluÅŸturmak iÃ§in Ã¶nce bir dokÃ¼man yÃ¼klemeniz gerekiyor.\n\n"
                           "ğŸ’¡ **NasÄ±l dokÃ¼man yÃ¼kleyebilirim?**\n"
                           "â€¢ Sol Ã¼stteki **'PDF YÃ¼kle'** butonuna tÄ±klayÄ±n\n"
                           "â€¢ PDF dosyanÄ±zÄ± seÃ§in (metin, resim, el yazÄ±sÄ± desteklenir)\n"
                           "â€¢ YÃ¼kleme tamamlandÄ±ktan sonra 'test oluÅŸtur' yazabilirsiniz\n\n"
                           f"ğŸ“Š **Mevcut durum:** {vector_stats.get('total_documents', 0)} dokÃ¼man, "
                           f"{vector_stats.get('total_chunks', 0)} metin parÃ§asÄ±")
            
            state["messages"].append(AIMessage(content=error_message))
            state["full_document_text"] = ""
        else:
            logger.info(f"âœ… Test iÃ§in dokÃ¼man bulundu: {len(full_text)} karakter")
            state["full_document_text"] = full_text
            
        return state

    async def ask_test_parameters_node(self, state: ConversationState) -> ConversationState:
        """KullanÄ±cÄ±dan test parametrelerini almak iÃ§in etkileÅŸimli dÃ¼ÄŸÃ¼m - TEK SEFERDE UI GÃ–NDERÄ°M"""
        try:
            current_stage = state.get("test_param_stage", "question_types")
            
            # SORUN 1: Ã‡oklu UI mesajlarÄ± Ã¶nlemek iÃ§in kontrol ekle
            if state.get("ui_message_sent"):
                logger.info("âš ï¸ UI mesajÄ± zaten gÃ¶nderildi, tekrar gÃ¶nderilmiyor")
                return state
            
            # Ä°lk kez Ã§aÄŸrÄ±lÄ±yorsa, parametreleri sÄ±fÄ±rla
            if not state.get("awaiting_test_params"):
                state["awaiting_test_params"] = True
                state["test_param_stage"] = "question_types"
                state["partial_test_params"] = {}
                state["test_params_ready"] = False
                current_stage = "question_types"
                
                logger.info("ğŸ¯ Test parametreleri isteniyor - ilk aÅŸama baÅŸlatÄ±lÄ±yor")
            
            # UI mesajÄ±nÄ± sadece bir kez gÃ¶nder
            state["ui_message_sent"] = True
            
            if current_stage == "question_types":
                # Soru tÃ¼rleri seÃ§im mesajÄ± gÃ¶nder
                question_types_message = {
                    "type": "test_parameters_request",
                    "stage": "question_types",
                    "content": "ğŸ¯ **Test OluÅŸturma AyarlarÄ±**\n\n**1. Hangi soru tÃ¼rlerini ve kaÃ§ar tane istiyorsunuz?**\n\nHer soru tÃ¼rÃ¼ iÃ§in 0-20 arasÄ± sayÄ± belirleyebilirsiniz:",
                    "options": [
                        {
                            "id": "coktan_secmeli", 
                            "label": "Ã‡oktan SeÃ§meli Sorular", 
                            "description": "A, B, C, D ÅŸÄ±klÄ± sorular",
                            "selected": True,
                            "default_count": 5,
                            "max_count": 20
                        },
                        {
                            "id": "klasik", 
                            "label": "Klasik (AÃ§Ä±k UÃ§lu) Sorular", 
                            "description": "Uzun cevap gerektiren sorular",
                            "selected": True,
                            "default_count": 3,
                            "max_count": 10
                        },
                        {
                            "id": "bosluk_doldurma", 
                            "label": "BoÅŸluk Doldurma SorularÄ±", 
                            "description": "Eksik kelime/kavram tamamlama",
                            "selected": False,
                            "default_count": 2,
                            "max_count": 15
                        },
                        {
                            "id": "dogru_yanlis", 
                            "label": "DoÄŸru-YanlÄ±ÅŸ SorularÄ±", 
                            "description": "Ä°ki seÃ§enekli doÄŸruluk sorularÄ±",
                            "selected": False,
                            "default_count": 5,
                            "max_count": 20
                        }
                    ],
                    "next_button_text": "Devam Et",
                    "chat_id": self.chat_id
                }
                
                # AI mesajÄ± ekle (kullanÄ±cÄ±ya gÃ¶rÃ¼nÃ¼r olan kÄ±sÄ±m)
                ui_message = ("ğŸ¯ **Test AyarlarÄ±**\n\n"
                            "Test oluÅŸturmak iÃ§in Ã¶nce birkaÃ§ ayar yapalÄ±m:\n\n"
                            "**1. Soru TÃ¼rleri:** Hangi tÃ¼rde sorular istiyorsunuz?\n"
                            "**2. Zorluk Seviyesi:** Kolay, Orta veya Zor?\n"
                            "**3. Ã–ÄŸrenci Seviyesi:** Hedef kitle hangi seviyede?\n\n"
                            "YukarÄ±daki menÃ¼den seÃ§imlerinizi yapÄ±n â¬†ï¸")
                
                state["messages"].append(AIMessage(content=ui_message))
                
            elif current_stage == "difficulty":
                # Zorluk seviyesi mesajÄ± gÃ¶nder
                question_types_message = {
                    "type": "test_parameters_request",
                    "stage": "difficulty",
                    "content": "**2. Testin zorluk seviyesini seÃ§in:**",
                    "options": [
                        {"id": "kolay", "label": "Kolay", "description": "Temel kavramlar ve basit uygulamalar", "selected": False},
                        {"id": "orta", "label": "Orta", "description": "Orta seviye analiz ve uygulama", "selected": True},
                        {"id": "zor", "label": "Zor", "description": "Ä°leri seviye analiz ve sentez", "selected": False}
                    ],
                    "next_button_text": "Devam Et",
                    "chat_id": self.chat_id
                }
                
            elif current_stage == "student_level":
                # Ã–ÄŸrenci seviyesi mesajÄ± gÃ¶nder
                question_types_message = {
                    "type": "test_parameters_request",
                    "stage": "student_level",
                    "content": "**3. Hedef Ã¶ÄŸrenci seviyesini seÃ§in:**",
                    "options": [
                        {"id": "ortaokul", "label": "Ortaokul (5-8. SÄ±nÄ±f)", "description": "Temel kavramlar ve basit aÃ§Ä±klamalar", "selected": False},
                        {"id": "lise", "label": "Lise (9-12. SÄ±nÄ±f)", "description": "DetaylÄ± analiz ve kavramsal baÄŸlantÄ±lar", "selected": True},
                        {"id": "universite", "label": "Ãœniversite", "description": "Ä°leri seviye akademik iÃ§erik", "selected": False},
                        {"id": "yetiskin", "label": "YetiÅŸkin EÄŸitimi", "description": "Pratik odaklÄ± Ã¶ÄŸrenme", "selected": False}
                    ],
                    "next_button_text": "Testi OluÅŸtur",
                    "chat_id": self.chat_id
                }
            
            # WebSocket mesajÄ±nÄ± gÃ¶nder
            if self.websocket_callback:
                await self.websocket_callback(json.dumps(question_types_message))
                logger.info(f"ğŸ“¤ Test parametreleri UI mesajÄ± gÃ¶nderildi - Stage: {current_stage}")
                
        except Exception as e:
            error_message = f"ÃœzgÃ¼nÃ¼m, test parametreleri alÄ±nÄ±rken bir hata oluÅŸtu: {str(e)}"
            state["messages"].append(AIMessage(content=error_message))
            logger.error(f"âŒ Ask test parameters error (Chat: {self.chat_id}): {e}")
        
        return state

    async def process_test_parameters_node(self, state: ConversationState) -> ConversationState:
        """KullanÄ±cÄ±dan gelen test parametrelerini iÅŸler - SORUN 2 DÃœZELTÄ°LMÄ°Å"""
        try:
            # EÄŸer test parametresi beklemiyorsak, bu dÃ¼ÄŸÃ¼mÃ¼n Ã§alÄ±ÅŸmamasÄ± gerekir.
            if not state.get("awaiting_test_params"):
                logger.info("âŒ Test parametreleri beklenmiyor, normal sohbete devam ediliyor.")
                state["current_intent"] = "gemini" 
                return state

            # Mevcut aÅŸamayÄ± ve Ã¶nceden doldurulmuÅŸ parametreleri state'ten al.
            current_stage = state.get("test_param_stage", "question_types")
            all_params = state.get("partial_test_params", {})
            
            logger.info(f"ğŸ”„ Parametreler iÅŸleniyor - AÅŸama: {current_stage}, Mevcut Params: {all_params}")

            # SORUN 2: UI mesaj flag'ini sÄ±fÄ±rla ki bir sonraki aÅŸamada UI gÃ¶nderilebilsin
            state["ui_message_sent"] = False

            # Gelen parametrelere gÃ¶re bir sonraki aÅŸamayÄ± belirle
            if current_stage == "question_types":
                # ArayÃ¼zden "soru_turleri" verisi geldi mi diye kontrol et.
                if "soru_turleri" in all_params:
                    state["test_param_stage"] = "difficulty"
                    logger.info(f"âœ… Soru tÃ¼rleri iÅŸlendi: {all_params['soru_turleri']}, bir sonraki aÅŸama: 'difficulty'")
                else:
                    # Gerekli parametre yoksa, bir hata olduÄŸunu varsay ve dÃ¶ngÃ¼yÃ¼ kÄ±r.
                    logger.warning("âš ï¸ 'soru_turleri' parametresi state iÃ§inde bulunamadÄ±.")
                    state["awaiting_test_params"] = False
                    state["messages"].append(AIMessage(content="Test parametreleri alÄ±nÄ±rken bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."))
                    return state

            elif current_stage == "difficulty":
                # ArayÃ¼zden "zorluk_seviyesi" verisi geldi mi diye kontrol et.
                if "zorluk_seviyesi" in all_params:
                    state["test_param_stage"] = "student_level"
                    logger.info(f"âœ… Zorluk seviyesi iÅŸlendi: {all_params['zorluk_seviyesi']}, bir sonraki aÅŸama: 'student_level'")
                else:
                    logger.warning("âš ï¸ 'zorluk_seviyesi' parametresi state iÃ§inde bulunamadÄ±.")
                    state["awaiting_test_params"] = False
                    state["messages"].append(AIMessage(content="Test parametreleri alÄ±nÄ±rken bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."))
                    return state
                    
            elif current_stage == "student_level":
                # ArayÃ¼zden "ogrenci_seviyesi" verisi geldi mi diye kontrol et.
                if "ogrenci_seviyesi" in all_params:
                    # TÃ¼m parametreler tamamlandÄ±. Test Ã¼retimine geÃ§ilebilir.
                    state["test_param_stage"] = "complete"
                    state["test_params_ready"] = True
                    state["awaiting_test_params"] = False
                    
                    # SORUN 2: Parametreleri doÄŸru formatta kaydet
                    final_params = {
                        "soru_turleri": all_params.get("soru_turleri", {}),
                        "zorluk_seviyesi": all_params.get("zorluk_seviyesi", "orta"),
                        "ogrenci_seviyesi": all_params.get("ogrenci_seviyesi", "lise")
                    }
                    
                    state["test_parameters"] = final_params
                    state["partial_test_params"] = final_params  # Ä°kisini de gÃ¼ncelle
                    
                    logger.info(f"ğŸ¯ TÃ¼m test parametreleri tamamlandÄ± ve kaydedildi: {final_params}")
                    
                    # KullanÄ±cÄ±ya parametrelerin alÄ±ndÄ±ÄŸÄ±nÄ± bildiren mesaj
                    total_questions = sum(final_params["soru_turleri"].values()) if final_params["soru_turleri"] else 8
                    
                    confirmation_message = (
                        f"âœ… **Test parametreleri ayarlandÄ±!**\n\n"
                        f"ğŸ¯ **Soru tÃ¼rleri:** "
                    )
                    
                    # Soru tÃ¼rlerini gÃ¼zel formatta gÃ¶ster
                    soru_turleri_text = []
                    for tur, sayi in final_params["soru_turleri"].items():
                        if sayi > 0:
                            tur_adi = {
                                "coktan_secmeli": "Ã‡oktan SeÃ§meli",
                                "klasik": "Klasik (AÃ§Ä±k UÃ§lu)", 
                                "bosluk_doldurma": "BoÅŸluk Doldurma",
                                "dogru_yanlis": "DoÄŸru-YanlÄ±ÅŸ"
                            }.get(tur, tur)
                            soru_turleri_text.append(f"{tur_adi}: {sayi}")
                    
                    confirmation_message += ", ".join(soru_turleri_text)
                    confirmation_message += (
                        f"\nğŸ“Š **Zorluk:** {final_params['zorluk_seviyesi'].title()}"
                        f"\nğŸ“ **Seviye:** {final_params['ogrenci_seviyesi'].title()}"
                        f"\nğŸ”¢ **Toplam soru:** {total_questions}\n\n"
                        f"ğŸ”„ Test sorularÄ±nÄ± oluÅŸturuyorum, bu iÅŸlem 3-5 dakika sÃ¼rebilir..."
                    )
                    
                    state["messages"].append(AIMessage(content=confirmation_message))
                    
                else:
                    logger.warning("âš ï¸ 'ogrenci_seviyesi' parametresi state iÃ§inde bulunamadÄ±.")
                    state["awaiting_test_params"] = False
                    state["messages"].append(AIMessage(content="Test parametreleri alÄ±nÄ±rken bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."))
                    return state
            
            # Bu dÃ¼ÄŸÃ¼m artÄ±k UI gÃ¶ndermez. Sadece state'i gÃ¼nceller.
            # YÃ¶nlendirme (routing) iÅŸlemi, grafikteki bir sonraki kenar tarafÄ±ndan yapÄ±lÄ±r.
            return state
        
        except Exception as e:
            error_message = f"Test parametreleri iÅŸlenirken kritik bir hata oluÅŸtu: {str(e)}"
            logger.error(f"âŒ Process test parameters error: {e}", exc_info=True)
            state["messages"].append(AIMessage(content=error_message))
            state["awaiting_test_params"] = False
            state["test_params_ready"] = False
            return state

    async def generate_test_questions_node(self, state: ConversationState) -> ConversationState:
        """CrewAI kullanarak test sorularÄ±nÄ± Ã¼retir - SORUN 2 DÃœZELTÄ°LMÄ°Å"""
        logger.info("ğŸš€ STEP: Generating test questions with CrewAI...")
        document_content = state["full_document_text"]
        
        if not document_content:
            error_msg = "DokÃ¼man iÃ§eriÄŸi bulunamadÄ±, test oluÅŸturulamÄ±yor."
            logger.error(f"âŒ {error_msg}")
            state["messages"].append(AIMessage(content=error_msg))
            return state
        
        logger.info(f"ğŸ“„ DokÃ¼man uzunluÄŸu: {len(document_content)} karakter")
        
        test_params = state.get("test_parameters", {})
        
        if not test_params:
            error_msg = "Test parametreleri bulunamadÄ±. LÃ¼tfen tekrar 'test oluÅŸtur' yazÄ±n."
            logger.error(f"âŒ {error_msg}")
            state["messages"].append(AIMessage(content=error_msg))
            return state
        
        # Parametreleri doÄŸru ÅŸekilde Ã§Ä±kar
        question_types = test_params.get("soru_turleri", {'coktan_secmeli': 5, 'klasik': 3})
        difficulty_level = test_params.get("zorluk_seviyesi", "orta")
        student_level = test_params.get("ogrenci_seviyesi", "lise")
        
        # SORUN 2: Toplam soru sayÄ±sÄ±nÄ± doÄŸru hesapla
        total_questions = sum(question_types.values()) if isinstance(question_types, dict) else 8
        
        preferences = {
            "soru_turleri": question_types,
            "zorluk_seviyesi": difficulty_level,
            "ogrenci_seviyesi": student_level,
            "toplam_soru": total_questions
        }
        
        logger.info(f"ğŸ¯ DOÄRU Test Parametreleri: {preferences}")
        
        if self.websocket_callback:
            await self.websocket_callback(json.dumps({
                "type": "system",
                "content": f"ğŸ§  {total_questions} soruluk test hazÄ±rlÄ±yorum... CrewAI sistemini baÅŸlatÄ±yorum.",
                "timestamp": datetime.utcnow().isoformat(),
                "chat_id": self.chat_id
            }))
        
        try:
            # CrewAI'yi asenkron olarak Ã§alÄ±ÅŸtÄ±r
            logger.info("ğŸ¤– CrewAI test sistemi baÅŸlatÄ±lÄ±yor...")
            
            generated_data = await self.test_crew.generate_questions(document_content, preferences)
            logger.info(f"âœ… CrewAI test sistemi tamamlandÄ±. SonuÃ§: {type(generated_data)}")
            
            # SonuÃ§ kontrolÃ¼ ve hata yÃ¶netimi
            if generated_data and not generated_data.get("error"):
                state["generated_questions"] = generated_data
                logger.info("âœ… Test sorularÄ± baÅŸarÄ±yla oluÅŸturuldu")
                
                # BaÅŸarÄ± mesajÄ± gÃ¶nder
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "crew_progress",
                        "message": "ğŸ‰ Test sorularÄ± baÅŸarÄ±yla oluÅŸturuldu!",
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id
                    }))
            else:
                error_msg = generated_data.get("error", "Test oluÅŸturma sÄ±rasÄ±nda bilinmeyen hata") if generated_data else "CrewAI'den yanÄ±t alÄ±namadÄ±"
                logger.error(f"âŒ CrewAI hatasÄ±: {error_msg}")
                state["generated_questions"] = {"error": error_msg}
                
                # Hata mesajÄ± gÃ¶nder
                if self.websocket_callback:
                    await self.websocket_callback(json.dumps({
                        "type": "error",
                        "message": f"âŒ Test oluÅŸturma hatasÄ±: {error_msg}",
                        "timestamp": datetime.utcnow().isoformat(),
                        "chat_id": self.chat_id
                    }))
                
        except Exception as e:
            error_msg = f"CrewAI test oluÅŸturma hatasÄ±: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            state["generated_questions"] = {"error": error_msg}
            
            # DetaylÄ± hata bilgisi gÃ¶nder
            if self.websocket_callback:
                await self.websocket_callback(json.dumps({
                    "type": "error",
                    "message": f"Test oluÅŸturma hatasÄ±: {error_msg}",
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }))
        
        # Her durumda state'i gÃ¼ncelle - bu kritik!
        logger.info("ğŸ“‹ Test oluÅŸturma node'u tamamlandÄ±, present_test_results'a geÃ§iliyor...")
        return state

    async def present_test_results_node(self, state: ConversationState) -> ConversationState:
        """Test sonuÃ§larÄ±nÄ± kullanÄ±cÄ±ya sunar"""
        logger.info("ğŸ¯ STEP: Presenting test results...")
        
        generated_questions = state.get("generated_questions", {})
        
        if "error" in generated_questions:
            error_msg = f"âŒ Test oluÅŸturma hatasÄ±: {generated_questions['error']}"
            logger.error(error_msg)
            state["messages"].append(AIMessage(content=error_msg))
            return state
        
        if not generated_questions:
            error_msg = "âŒ Test sorularÄ± oluÅŸturulamadÄ± - boÅŸ sonuÃ§."
            logger.error(error_msg)
            state["messages"].append(AIMessage(content=error_msg))
            return state
        
        try:
            # Test parametrelerinden bilgileri al - DOÄRU KAYNAK
            test_params = state.get("partial_test_params", {})
            if not test_params:
                test_params = state.get("test_parameters", {})
                
            question_types = test_params.get("soru_turleri", {})
            total_questions = sum(question_types.values()) if question_types else 0
            
            # Test baÅŸarÄ± mesajÄ± oluÅŸtur
            success_message = f"ğŸ‰ **Test BaÅŸarÄ±yla OluÅŸturuldu!**\n\n"
            success_message += f"ğŸ“Š **Test DetaylarÄ±:**\n"
            success_message += f"â€¢ **Toplam Soru:** {total_questions}\n"
            success_message += f"â€¢ **Zorluk:** {test_params.get('zorluk_seviyesi', 'orta').title()}\n"
            success_message += f"â€¢ **Seviye:** {test_params.get('ogrenci_seviyesi', 'lise').title()}\n\n"
            
            # Soru tÃ¼rleri detayÄ±
            if question_types:
                success_message += f"ğŸ¯ **Soru DaÄŸÄ±lÄ±mÄ±:**\n"
                type_labels = {
                    "coktan_secmeli": "Ã‡oktan SeÃ§meli",
                    "klasik": "Klasik (AÃ§Ä±k UÃ§lu)",
                    "bosluk_doldurma": "BoÅŸluk Doldurma",
                    "dogru_yanlis": "DoÄŸru-YanlÄ±ÅŸ"
                }
                
                for type_id, count in question_types.items():
                    if count > 0:
                        type_name = type_labels.get(type_id, type_id)
                        success_message += f"â€¢ **{type_name}:** {count} soru\n"
                
                success_message += "\n"
            
            success_message += f"ğŸš€ **HazÄ±r!** AÅŸaÄŸÄ±daki **'Testi Ã‡Ã¶z'** butonuna tÄ±klayarak testinizi baÅŸlatabilirsiniz.\n"
            success_message += f"ğŸ“ Test sonuÃ§larÄ±nÄ±z otomatik olarak deÄŸerlendirilecek ve eksik konularÄ±nÄ±z belirlenecek."
            
            # Test sonuÃ§larÄ±nÄ± WebSocket Ã¼zerinden gÃ¶nder
            if self.websocket_callback:
                test_message = {
                    "type": "test_generated",
                    "content": success_message,
                    "questions": generated_questions,
                    "test_parameters": test_params,
                    "timestamp": datetime.utcnow().isoformat(),
                    "chat_id": self.chat_id
                }
                
                await self.websocket_callback(json.dumps(test_message))
                logger.info("âœ… Test sonuÃ§larÄ± WebSocket Ã¼zerinden gÃ¶nderildi")
            
            # State'e de mesajÄ± ekle
            state["messages"].append(AIMessage(content=success_message))
            
            # Test tamamlandÄ±ktan sonra state'i temizle
            state["awaiting_test_params"] = False
            state["test_param_stage"] = "start"
            state["test_params_ready"] = False
            state["partial_test_params"] = {}
            state["ui_message_sent"] = False  # UI mesaj flag'ini temizle
            
        except Exception as e:
            error_msg = f"Test sonuÃ§larÄ± sunulurken hata oluÅŸtu: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            state["messages"].append(AIMessage(content=error_msg))
        
        return state